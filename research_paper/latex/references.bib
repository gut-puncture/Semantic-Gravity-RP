@inproceedings{ouyang2022training,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022},
  publisher={Curran Associates, Inc.}
}

@inproceedings{wei2022finetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@inproceedings{kassner2020negated,
  title={Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly},
  author={Kassner, Nora and Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7811--7818},
  year={2020},
  publisher={Association for Computational Linguistics}
}

@inproceedings{hossain2022analysis,
  title={An Analysis of Negation in Natural Language Inference},
  author={Hossain, Md Mosharaf and Blanco, Eduardo and Kautz, Henry},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={5383--5395},
  year={2022},
  publisher={Association for Computational Linguistics}
}

@article{nostalgebraist2020logitlens,
  title={Interpreting {GPT}: The Logit Lens},
  author={nostalgebraist},
  journal={LessWrong},
  year={2020},
  note={Available at \url{https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens}}
}

@inproceedings{geva2022transformer,
  title={Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin and Goldberg, Yoav},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={30--45},
  year={2022},
  publisher={Association for Computational Linguistics}
}

@inproceedings{meng2022locating,
  title={Locating and Editing Factual Associations in {GPT}},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={17359--17372},
  year={2022},
  publisher={Curran Associates, Inc.}
}

@inproceedings{wang2023interpretability,
  title={Interpretability in the Wild: A Circuit for Indirect Object Identification in {GPT-2} Small},
  author={Wang, Kevin and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=NpsVSN6o4ul}
}

@inproceedings{zhao2021calibrate,
  title={Calibrate Before Use: Improving Few-Shot Performance of Language Models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  publisher={PMLR}
}

@inproceedings{lu2022fantastically,
  title={Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages={8086--8098},
  year={2022},
  publisher={Association for Computational Linguistics}
}
