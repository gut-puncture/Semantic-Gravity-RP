{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Semantic Gravity Experiment Pipeline\n",
                "\n",
                "This notebook runs the complete Semantic Gravity experiment pipeline:\n",
                "1. Setup and dependencies\n",
                "2. Inference (greedy + sampling)\n",
                "3. Behavior analysis\n",
                "4. Mechanistic metrics\n",
                "5. Activation patching\n",
                "6. Bootstrap CIs\n",
                "7. Visualization"
            ],
            "metadata": {
                "id": "title_cell"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch transformers accelerate tokenizers numpy pandas scipy matplotlib tqdm requests wordfreq"
            ],
            "metadata": {
                "id": "install_deps"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ],
            "metadata": {
                "id": "mount_drive"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "\n",
                "# Set paths - UPDATE THESE FOR YOUR SETUP\n",
                "REPO_DIR = '/content/drive/MyDrive/Semantic_Gravity'  # Path to repo in Drive\n",
                "MODEL_DIR = '/content/drive/MyDrive/models/your_model'  # Path to model weights\n",
                "\n",
                "os.chdir(REPO_DIR)\n",
                "print(f'Working directory: {os.getcwd()}')"
            ],
            "metadata": {
                "id": "set_paths"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Check GPU\n",
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "if torch.cuda.is_available():\n",
                "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
                "else:\n",
                "    print('No GPU available')"
            ],
            "metadata": {
                "id": "check_gpu"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "import sys\n",
                "sys.path.insert(0, REPO_DIR)\n",
                "\n",
                "# Set environment variables if needed\n",
                "# os.environ['DEEPSEEK_API_KEY'] = 'your_key_here'  # For dataset generation\n",
                "\n",
                "print('Repository added to path')"
            ],
            "metadata": {
                "id": "setup_path"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# OPTIONAL: Run dataset pipeline (uncomment if needed)\n",
                "# from src.dataset_pipeline import build_dataset\n",
                "# build_dataset()"
            ],
            "metadata": {
                "id": "dataset_pipeline"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Run inference\n",
                "from src.config import setup_directories\n",
                "\n",
                "RUN_ROOT = setup_directories()['run_root']\n",
                "print(f'Run root: {RUN_ROOT}')\n",
                "\n",
                "from src.runner import run_experiment\n",
                "run_experiment(output_root=RUN_ROOT, limit=None)"
            ],
            "metadata": {
                "id": "run_inference"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Run behavior analysis\n",
                "from src.behavior_analysis import run_behavior_analysis_pipeline\n",
                "run_behavior_analysis_pipeline(output_root=RUN_ROOT)"
            ],
            "metadata": {
                "id": "behavior_analysis"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Run mechanistic metrics\n",
                "from src.metrics_attn import run_mechanistic_metrics_pipeline\n",
                "run_mechanistic_metrics_pipeline(output_root=RUN_ROOT)"
            ],
            "metadata": {
                "id": "mechanistic_metrics"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Run activation patching\n",
                "from src.patching import run_activation_patching_pipeline\n",
                "run_activation_patching_pipeline(output_root=RUN_ROOT)"
            ],
            "metadata": {
                "id": "activation_patching"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Run bootstrap CIs and visualization\n",
                "from src.bootstrap import run_bootstrap_pipeline\n",
                "from src.visualize import run_visualization_pipeline\n",
                "\n",
                "run_bootstrap_pipeline(output_root=RUN_ROOT)\n",
                "result_paths = run_visualization_pipeline(output_root=RUN_ROOT)\n",
                "\n",
                "print('\\nGenerated outputs:')\n",
                "for name, path in result_paths.items():\n",
                "    print(f'  {name}: {path}')"
            ],
            "metadata": {
                "id": "bootstrap_viz"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}