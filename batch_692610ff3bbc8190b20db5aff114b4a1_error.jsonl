{"id": "batch_req_692611b6b614819089c855466bc72268", "custom_id": "gpt-5-2025-08-07-0", "response": {"status_code": 400, "request_id": "c56414bcadaa2165bd3c331dda50a7f2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6c9d081909270936b7fb97d74", "custom_id": "gpt-5-2025-08-07-1", "response": {"status_code": 400, "request_id": "a523c8bb75bf8dc06da3be35e0477850", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6c4088190885a14167828624b", "custom_id": "gpt-5-2025-08-07-2", "response": {"status_code": 400, "request_id": "b3bc685dc55f907d2dd26b2e241407d6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b71bb481908474a93270ef9a87", "custom_id": "gpt-5-2025-08-07-3", "response": {"status_code": 400, "request_id": "b8ce5f5f0c2937e61355395479cc9747", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6d31c8190a52c60ff407e4798", "custom_id": "gpt-5-2025-08-07-4", "response": {"status_code": 400, "request_id": "e36cd8a283f83ba45b3c702f9a4fb88c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6cc608190890242fc517669ac", "custom_id": "gpt-5-2025-08-07-5", "response": {"status_code": 400, "request_id": "fcf6c84a25e88f788b2e975f9ee003f0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6c8648190a23aa404b9cba29e", "custom_id": "gpt-5-2025-08-07-6", "response": {"status_code": 400, "request_id": "5fe44a911eef3ad8ea9ab1d0e0081b80", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6f83c8190b693c765163a1bef", "custom_id": "gpt-5-2025-08-07-7", "response": {"status_code": 400, "request_id": "9031e35e7f1ae2c12b6835537d30f6c1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6bc4c8190baa12852de5528b1", "custom_id": "gpt-5-2025-08-07-8", "response": {"status_code": 400, "request_id": "c134567cf031af85a40e4d08b8f96354", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b6c66481909cccf0b35f300e98", "custom_id": "gpt-5-2025-08-07-9", "response": {"status_code": 400, "request_id": "bf31eb8cdc9587f5e5b4e385367f16c3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b72388819087fd408d5a547646", "custom_id": "gpt-5-2025-08-07-10", "response": {"status_code": 400, "request_id": "b9acc7fd4c6908396e246df2b2c92323", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b87f248190a67a02a213d25459", "custom_id": "gpt-5-2025-08-07-11", "response": {"status_code": 400, "request_id": "3da0bdb24586a7b1e79fc2cac6323005", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b72f8c8190ba6b56b7be8c15f2", "custom_id": "gpt-5-2025-08-07-12", "response": {"status_code": 400, "request_id": "0a535f5e2aedc462617a13dd3ed8ea8e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b730f88190875dbcd21a141d20", "custom_id": "gpt-5-2025-08-07-13", "response": {"status_code": 400, "request_id": "1d70c6e74dc11b513e44ef7b23bee67a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7348081909805a2dff2e4e8f4", "custom_id": "gpt-5-2025-08-07-14", "response": {"status_code": 400, "request_id": "5dce586ba5229d648c9a3c5613340216", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b732788190981aecc58c9236aa", "custom_id": "gpt-5-2025-08-07-15", "response": {"status_code": 400, "request_id": "76a93a7daf7de55bce2c6b2ebdc97bc7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b735d08190a69f1d6c91d3f043", "custom_id": "gpt-5-2025-08-07-16", "response": {"status_code": 400, "request_id": "6a77f81b97df536eafda8240b1c1738e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b73d688190836a73e692f735e3", "custom_id": "gpt-5-2025-08-07-17", "response": {"status_code": 400, "request_id": "fa2849d31c7ecfa7e2cfa4a924eefc5d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7609c8190aa461946ea086d50", "custom_id": "gpt-5-2025-08-07-18", "response": {"status_code": 400, "request_id": "f1cf342e5bb21617287bf73811ca8d01", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7870c81909992b1ed786a9083", "custom_id": "gpt-5-2025-08-07-19", "response": {"status_code": 400, "request_id": "4029b677ec0c5f4eebc251a54e4e26c3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b78c708190b95f5a44b7803283", "custom_id": "gpt-5-2025-08-07-20", "response": {"status_code": 400, "request_id": "4528c1a518208cf96207265b836d6c3c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7a45c8190aff4ce2decd20569", "custom_id": "gpt-5-2025-08-07-21", "response": {"status_code": 400, "request_id": "b082becf5857685cb185d4b553c164c0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7a3b8819094308ce06580427e", "custom_id": "gpt-5-2025-08-07-22", "response": {"status_code": 400, "request_id": "dccd390d19d426a4b69aadf2dc706cfb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7a8008190aff96bff751b210e", "custom_id": "gpt-5-2025-08-07-23", "response": {"status_code": 400, "request_id": "5cbe588518bf209b0c2dd8c14da6e970", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7a0bc81908dcf378e409d638c", "custom_id": "gpt-5-2025-08-07-24", "response": {"status_code": 400, "request_id": "b36e203c2ad028bff7c9ae4b2506e851", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b79f688190a13d43f11b5987c6", "custom_id": "gpt-5-2025-08-07-25", "response": {"status_code": 400, "request_id": "bfe6d12168530af60874b25a366c9391", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7af688190bf6131887bf8242a", "custom_id": "gpt-5-2025-08-07-26", "response": {"status_code": 400, "request_id": "055723504f5619942b7e291ddd9dc077", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7cf048190b7d6e8d28ba8916e", "custom_id": "gpt-5-2025-08-07-27", "response": {"status_code": 400, "request_id": "3f014f15a785f51e314066360af79c2e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7f1088190aeeac4e97fd4a618", "custom_id": "gpt-5-2025-08-07-28", "response": {"status_code": 400, "request_id": "e4c4f190616ef59806626964b47edaf3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b7f59c81908da1ca9ab1634305", "custom_id": "gpt-5-2025-08-07-29", "response": {"status_code": 400, "request_id": "8f9530752a83568c727cf66eb357f860", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b80f4481909c6d1021ebf7f9b2", "custom_id": "gpt-5-2025-08-07-30", "response": {"status_code": 400, "request_id": "a902ebde89b8af17c43d82aa0fdb3102", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b817b48190a809551ac31fa022", "custom_id": "gpt-5-2025-08-07-31", "response": {"status_code": 400, "request_id": "ca484a4373a19b7a8ee832e871d1dd08", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b811b081908dca4a6f0a443de2", "custom_id": "gpt-5-2025-08-07-32", "response": {"status_code": 400, "request_id": "c84d88ff9212099cf4ed67c6dede5859", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8152481908efa90963518a00f", "custom_id": "gpt-5-2025-08-07-33", "response": {"status_code": 400, "request_id": "360a0f5a2300522703d5251b8ea314fa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8119c8190834b44f6aad6e19e", "custom_id": "gpt-5-2025-08-07-34", "response": {"status_code": 400, "request_id": "87bca64080d8325f3df9e5493c9075bc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b81c2c81909270b5454e81f60e", "custom_id": "gpt-5-2025-08-07-35", "response": {"status_code": 400, "request_id": "26c676f279d7f1498adc2e32aa4c00b9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b84834819085f64621689d9e20", "custom_id": "gpt-5-2025-08-07-36", "response": {"status_code": 400, "request_id": "81fc96491237f0f0dd242aba4a361e61", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b874ac819093e2a473d3984c82", "custom_id": "gpt-5-2025-08-07-37", "response": {"status_code": 400, "request_id": "0d6900a0fd20da8a80b0d413b0af56ac", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b86304819090f3f7ae779bd926", "custom_id": "gpt-5-2025-08-07-38", "response": {"status_code": 400, "request_id": "cea582e05e58f9a1dd45b859efc6a974", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8833c8190908915a148296f26", "custom_id": "gpt-5-2025-08-07-39", "response": {"status_code": 400, "request_id": "2ec92439dcf7a66193ab46404e516d3d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b880bc819091b7ade14098661a", "custom_id": "gpt-5-2025-08-07-40", "response": {"status_code": 400, "request_id": "210c5f0fc52c0eb181660466a2a6ba0d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b879a881908bbdcec568bed3d9", "custom_id": "gpt-5-2025-08-07-41", "response": {"status_code": 400, "request_id": "9b018bd0f9823e50905164e8c1f18a9d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8847481908799aa9b2f954352", "custom_id": "gpt-5-2025-08-07-42", "response": {"status_code": 400, "request_id": "eb82c4a6f8f8ba1d7769490cdbfaa7ef", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b87fb48190b1ee7a47759165b0", "custom_id": "gpt-5-2025-08-07-43", "response": {"status_code": 400, "request_id": "a84f4a26174a20c694aa2befae34614f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b88e98819089103de2615680e7", "custom_id": "gpt-5-2025-08-07-44", "response": {"status_code": 400, "request_id": "a1ef73ceb786f042e437c7b745427572", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8b3c48190afa0b2e948eac82b", "custom_id": "gpt-5-2025-08-07-45", "response": {"status_code": 400, "request_id": "09c4788a018f90dcc1baec0b4d30f474", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8d4ac81908a3cf534c30ead2d", "custom_id": "gpt-5-2025-08-07-46", "response": {"status_code": 400, "request_id": "7d73c1af3e04a126a2f3fac803b781f2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8f26881909ceaa73b464600ce", "custom_id": "gpt-5-2025-08-07-47", "response": {"status_code": 400, "request_id": "9adf2407a2128b37ae0b0f0960c3201a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8ec1c81909ebe9904903ca3d4", "custom_id": "gpt-5-2025-08-07-48", "response": {"status_code": 400, "request_id": "9abb9297841fc189fd5a029da987db41", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8f1d08190ab26f94772453488", "custom_id": "gpt-5-2025-08-07-49", "response": {"status_code": 400, "request_id": "e7ac55222b159fbdc50150a274cb3966", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8ef108190866dd58b04d3ad4a", "custom_id": "gpt-5-2025-08-07-50", "response": {"status_code": 400, "request_id": "01fadd007da080cabaec41887457886b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8f55481908bee431c27c5779e", "custom_id": "gpt-5-2025-08-07-51", "response": {"status_code": 400, "request_id": "17fb857d46b16316a292c82c6c7c1de4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8ed44819091b5dbcf9d7a1244", "custom_id": "gpt-5-2025-08-07-52", "response": {"status_code": 400, "request_id": "00d1e06d13731d16b17abd5e4e9ad653", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8f3d48190bfe945bc5c81885d", "custom_id": "gpt-5-2025-08-07-53", "response": {"status_code": 400, "request_id": "ff3edc8e22a3c801474b079cf89c873c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b8fa448190819e8d74f89e65da", "custom_id": "gpt-5-2025-08-07-54", "response": {"status_code": 400, "request_id": "1f35e91d3d848a843e7be3bf296d3073", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b923408190b4c07a3373d862d5", "custom_id": "gpt-5-2025-08-07-55", "response": {"status_code": 400, "request_id": "920590fbdf6b4fc636979da8f250e57f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b941c081909f06c683255b8a60", "custom_id": "gpt-5-2025-08-07-56", "response": {"status_code": 400, "request_id": "3639b301d3ca58fa1b2d76cbf4603e49", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b960b081908079bfe149e9e81d", "custom_id": "gpt-5-2025-08-07-57", "response": {"status_code": 400, "request_id": "b33cc92e0529394b3c97d650249eae57", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b960b88190a73e83f74a202660", "custom_id": "gpt-5-2025-08-07-58", "response": {"status_code": 400, "request_id": "cefbad70cc93f2370b27ef7665b838b9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9691c8190b3a95a82ad4e7b62", "custom_id": "gpt-5-2025-08-07-59", "response": {"status_code": 400, "request_id": "77dd617b3e873b5d5e5134d319287228", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b96c548190aba763c4173b7984", "custom_id": "gpt-5-2025-08-07-60", "response": {"status_code": 400, "request_id": "693c6dc45e10fd6fcdb19eb0a0a65716", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9631c8190b9d456b4bb363b82", "custom_id": "gpt-5-2025-08-07-61", "response": {"status_code": 400, "request_id": "cd3d2cf73232e83b0013b2ac9e449a5c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b95c1c8190808948875dd516bf", "custom_id": "gpt-5-2025-08-07-62", "response": {"status_code": 400, "request_id": "c659146362ee3331ca60bf372d59e491", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b977f481909f2f41613a72ef29", "custom_id": "gpt-5-2025-08-07-63", "response": {"status_code": 400, "request_id": "f770537177b3acab460ef39d1478de54", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b96a4c8190985e1e94a43ca8ee", "custom_id": "gpt-5-2025-08-07-64", "response": {"status_code": 400, "request_id": "7715c7fca67999642f6a0dbf70b7a9ee", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b98be48190957775d624e0b576", "custom_id": "gpt-5-2025-08-07-65", "response": {"status_code": 400, "request_id": "2bfc563010cffc25f6885921fc24af2f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9b7788190ab3913dd6bf779a6", "custom_id": "gpt-5-2025-08-07-66", "response": {"status_code": 400, "request_id": "eeec0f25d49dd56aec4238d7fbaad678", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9d178819089f7d50db2c7dda3", "custom_id": "gpt-5-2025-08-07-67", "response": {"status_code": 400, "request_id": "601b88083bb0a57f77a867afa7b6f6ac", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9ecd881908ea39f7331ada6d5", "custom_id": "gpt-5-2025-08-07-68", "response": {"status_code": 400, "request_id": "9a5f2cbeb34b6c579943725bc9766499", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9d8d48190929ad6bb29b0f8ee", "custom_id": "gpt-5-2025-08-07-69", "response": {"status_code": 400, "request_id": "89a5bc82d62beac05bc4948791449f0b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9d738819083f91378ce134862", "custom_id": "gpt-5-2025-08-07-70", "response": {"status_code": 400, "request_id": "19e0d36adef8566d587227ccada40bc0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9dbe88190989d67ff2bc7c27b", "custom_id": "gpt-5-2025-08-07-71", "response": {"status_code": 400, "request_id": "d9ae96caba6a1b19a9d7ffbf261e4f3a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9db488190b2a60d0b3ba4517b", "custom_id": "gpt-5-2025-08-07-72", "response": {"status_code": 400, "request_id": "03df1956651addb84d416c0445c8e4ec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9e0188190a77f4c496eeb9d45", "custom_id": "gpt-5-2025-08-07-73", "response": {"status_code": 400, "request_id": "e7e7aef427364d89650767018aff7043", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611b9dec48190b8897e6e955c8816", "custom_id": "gpt-5-2025-08-07-74", "response": {"status_code": 400, "request_id": "541ff30f5024ac5bef5860be032632d3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba16bc8190a3665dc27ae59838", "custom_id": "gpt-5-2025-08-07-75", "response": {"status_code": 400, "request_id": "fddfbeacfdb5e5ae72113a9006983d9e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba39188190825b4fb9597471f7", "custom_id": "gpt-5-2025-08-07-76", "response": {"status_code": 400, "request_id": "ffa1fc6a99d2c8540a19a5411eea9509", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba3ab08190a0112b6276f0d569", "custom_id": "gpt-5-2025-08-07-77", "response": {"status_code": 400, "request_id": "32937a8b9337210d7a1bc169000bfeb4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba50c08190b83c46c63d54f953", "custom_id": "gpt-5-2025-08-07-78", "response": {"status_code": 400, "request_id": "f0e725b765554a7d9fa9c878cbbf293a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba3fb48190adafdf651d8e191a", "custom_id": "gpt-5-2025-08-07-79", "response": {"status_code": 400, "request_id": "0763bef7b42b02edf45f5893a417f426", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba57388190bc5403286144c8ad", "custom_id": "gpt-5-2025-08-07-80", "response": {"status_code": 400, "request_id": "ab48e477deb6df2ac08713ec65a2d3a8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba51448190a716457d0be0442e", "custom_id": "gpt-5-2025-08-07-81", "response": {"status_code": 400, "request_id": "bf88c9c477de5eb8d67ed4bf3346eeea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba4660819085b35dac4db73371", "custom_id": "gpt-5-2025-08-07-82", "response": {"status_code": 400, "request_id": "488268b8bc6e8d3252156a0516d94aee", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba4ad481908d7d65f636fc8894", "custom_id": "gpt-5-2025-08-07-83", "response": {"status_code": 400, "request_id": "838c0efb6ecdc0bb0d3e955d15c2d316", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ba5a848190a5cf034ce1e45807", "custom_id": "gpt-5-2025-08-07-84", "response": {"status_code": 400, "request_id": "fd9464fde598080db705e868ab84b14a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb6bc08190b14c4140dbb1c147", "custom_id": "gpt-5-2025-08-07-85", "response": {"status_code": 400, "request_id": "62eb52b49fcbf8c6d8d5a387b0f3ff62", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611baa5b08190806b94921e4da8ae", "custom_id": "gpt-5-2025-08-07-86", "response": {"status_code": 400, "request_id": "284a19bbf32aef4b3fba78ce26a79a40", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611baada88190b4d629cc2ade0fd9", "custom_id": "gpt-5-2025-08-07-87", "response": {"status_code": 400, "request_id": "8dfdf3d02e4cdca5ba8bc605d6cd2aba", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bac04881909f557b1d2607664e", "custom_id": "gpt-5-2025-08-07-88", "response": {"status_code": 400, "request_id": "d40b99fd3baab6b281bcb7d725ba4e23", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bab1008190a1af4fb45faaa480", "custom_id": "gpt-5-2025-08-07-89", "response": {"status_code": 400, "request_id": "beff81ffd19a53456dd40f151da84923", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bab2408190873477f9dc4113d7", "custom_id": "gpt-5-2025-08-07-90", "response": {"status_code": 400, "request_id": "d6d44ecd08e658b523c0d2d6f4050fa0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bab8308190b09adde96458448c", "custom_id": "gpt-5-2025-08-07-91", "response": {"status_code": 400, "request_id": "d0d011237c1815d756dea8c2214fa580", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611babe7c819083b438e6c2f93c98", "custom_id": "gpt-5-2025-08-07-92", "response": {"status_code": 400, "request_id": "65d855f21161990edb8d589b83297b1a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bac200819098882d6618428130", "custom_id": "gpt-5-2025-08-07-93", "response": {"status_code": 400, "request_id": "b6ba255472be556fff894e701e161525", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bac4e48190b872d5c3183f57fe", "custom_id": "gpt-5-2025-08-07-94", "response": {"status_code": 400, "request_id": "81dea3c2d987202538692f862fd3f090", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb16cc8190a34433537cd52436", "custom_id": "gpt-5-2025-08-07-95", "response": {"status_code": 400, "request_id": "7d6e179d0568d4a567bec0e0fea1b9fc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb21c8819086f013f0f4d6e4a7", "custom_id": "gpt-5-2025-08-07-96", "response": {"status_code": 400, "request_id": "a7bea2cd7fbe1dc46d1f7d0ea936de2d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb19b481908e90843f0b3d3de1", "custom_id": "gpt-5-2025-08-07-97", "response": {"status_code": 400, "request_id": "230770065834141fbd0b3d72c2dd1753", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb2720819084c057cb2b7461ee", "custom_id": "gpt-5-2025-08-07-98", "response": {"status_code": 400, "request_id": "599a0fe58f8c2fe87d887c7546a599ad", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb24888190a0c726de4102ce50", "custom_id": "gpt-5-2025-08-07-99", "response": {"status_code": 400, "request_id": "11573390bc8fe9b14ad8cbbb660c0c06", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb29dc8190a5f26c2e513b2aec", "custom_id": "gpt-5-2025-08-07-100", "response": {"status_code": 400, "request_id": "d9735a6c13a1bd64e07abcd6df4353ea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb2588819096b8824fa15facab", "custom_id": "gpt-5-2025-08-07-101", "response": {"status_code": 400, "request_id": "325e1d75d350a74911eb80103693a968", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb3144819090088c925a7eac73", "custom_id": "gpt-5-2025-08-07-102", "response": {"status_code": 400, "request_id": "6d7177f59140080714ab8164786ae48a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb29e88190a54607b4aa670795", "custom_id": "gpt-5-2025-08-07-103", "response": {"status_code": 400, "request_id": "3f797420dd012e4325eb20a48200269e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb7cd08190854e9f15baeec8f1", "custom_id": "gpt-5-2025-08-07-104", "response": {"status_code": 400, "request_id": "f49b48d3570ca5eeec464bf54cab6e54", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb84208190a5652a09052a704e", "custom_id": "gpt-5-2025-08-07-105", "response": {"status_code": 400, "request_id": "f7380bfac9ce933efc03289ebc9daee8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb89a88190850388de737621d7", "custom_id": "gpt-5-2025-08-07-106", "response": {"status_code": 400, "request_id": "1c51d42c29baaba9999ce4883577efc4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb8bbc8190a086eceb8ea56217", "custom_id": "gpt-5-2025-08-07-107", "response": {"status_code": 400, "request_id": "5503b2586ace088fe0fa10c59de7b486", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc2ae4819086f531a24111a59e", "custom_id": "gpt-5-2025-08-07-108", "response": {"status_code": 400, "request_id": "b66131fa69e38cef682ca292dea2713f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb8fd08190961b43dc949cd96e", "custom_id": "gpt-5-2025-08-07-109", "response": {"status_code": 400, "request_id": "edabfcf5e67f79eda90fc080c824f1e5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb99b4819086311ede63aae71f", "custom_id": "gpt-5-2025-08-07-110", "response": {"status_code": 400, "request_id": "46f95691e81e4bab479e6a46d4189178", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb92fc8190ad18413a94e4522c", "custom_id": "gpt-5-2025-08-07-111", "response": {"status_code": 400, "request_id": "d028ac39ea5df832aa62b971326325bb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bb95848190af586b41fe975682", "custom_id": "gpt-5-2025-08-07-112", "response": {"status_code": 400, "request_id": "54bf226865803d6baaacdec9b2041509", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbdf548190bc1c36d4e7c01c09", "custom_id": "gpt-5-2025-08-07-113", "response": {"status_code": 400, "request_id": "e415d4860a856fd64354084ca4863a87", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbe67881909d29d361d2aef00b", "custom_id": "gpt-5-2025-08-07-114", "response": {"status_code": 400, "request_id": "aa7ef91bf7c1443412940a5f5bba1244", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbed1081908c8fd3081a2ce08f", "custom_id": "gpt-5-2025-08-07-115", "response": {"status_code": 400, "request_id": "ac8a932fb192068ee8ebb0b4b255968f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbfab88190a412b1aa028bec0e", "custom_id": "gpt-5-2025-08-07-116", "response": {"status_code": 400, "request_id": "639f3d1f21106a197622dbd91d392f07", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbfc948190a064e298d92bf630", "custom_id": "gpt-5-2025-08-07-117", "response": {"status_code": 400, "request_id": "104ac4d49c6e9469e9ce0134f6f0cdc1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bbf8e481908a7e2b601d13a9ff", "custom_id": "gpt-5-2025-08-07-118", "response": {"status_code": 400, "request_id": "0a144f09c760d51348c35a7d7f78556a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc03648190b2e257232bd3153b", "custom_id": "gpt-5-2025-08-07-119", "response": {"status_code": 400, "request_id": "2c7312d6e17e74770928037bd77e0c48", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc00808190bb8e952a493d38cc", "custom_id": "gpt-5-2025-08-07-120", "response": {"status_code": 400, "request_id": "9167bf63104160cebd8346123fd31cb2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc183c8190b91332bf0f6be5a2", "custom_id": "gpt-5-2025-08-07-121", "response": {"status_code": 400, "request_id": "b7e7388f13b29d82f6a34a466cc72160", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc4cc88190aa361dba0f0cba20", "custom_id": "gpt-5-2025-08-07-122", "response": {"status_code": 400, "request_id": "d3da89727fae1a8fe2ff54a43744d22d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc6f4c8190aa0b8da01b7055bb", "custom_id": "gpt-5-2025-08-07-123", "response": {"status_code": 400, "request_id": "f65d212cf08010535ce5590a26349e04", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc5fb48190a93aac539c3b4149", "custom_id": "gpt-5-2025-08-07-124", "response": {"status_code": 400, "request_id": "67950d38d5feb76addc1988c8a01983b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc6f408190a6ec7c382aea2bbb", "custom_id": "gpt-5-2025-08-07-125", "response": {"status_code": 400, "request_id": "a7029127af2373e752ff7413be82b050", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc8d648190b04886c1d74f9205", "custom_id": "gpt-5-2025-08-07-126", "response": {"status_code": 400, "request_id": "2163131399d0b7b4f1ad5cb40577d861", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc773481909e4928bbd81c701a", "custom_id": "gpt-5-2025-08-07-127", "response": {"status_code": 400, "request_id": "bbd3add1b89d56e06dff3fd04fc69da2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc7e648190b198586b2c4f9257", "custom_id": "gpt-5-2025-08-07-128", "response": {"status_code": 400, "request_id": "6bef99de27a34ce89fd85cba7c9dd567", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc772081909021859ee7429058", "custom_id": "gpt-5-2025-08-07-129", "response": {"status_code": 400, "request_id": "a187005cbd78cc919ca957f2715cbfe6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc8ce48190a715311dc8366b5d", "custom_id": "gpt-5-2025-08-07-130", "response": {"status_code": 400, "request_id": "ed73adff35bc5d608e58a70e72d5a90a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bc962081908357a63480b18f99", "custom_id": "gpt-5-2025-08-07-131", "response": {"status_code": 400, "request_id": "8148bb4510675eb82a23c3e726337dea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcb4648190abe5a530d4b57dda", "custom_id": "gpt-5-2025-08-07-132", "response": {"status_code": 400, "request_id": "5d4565814ae92a76226ade00118b2dc9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcc3b48190a844ca1d2f620681", "custom_id": "gpt-5-2025-08-07-133", "response": {"status_code": 400, "request_id": "ad2a5f70ad6dcc24aedb192fc535cbf7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcda8c819086858e26a424c275", "custom_id": "gpt-5-2025-08-07-134", "response": {"status_code": 400, "request_id": "9889eda16cdafaa9678d768a3bc46de2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcf75c81908ca60ad1bf8b9f29", "custom_id": "gpt-5-2025-08-07-135", "response": {"status_code": 400, "request_id": "ee755d07eff9e052895362938b27e7b6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcdf948190ac7ebf989796920e", "custom_id": "gpt-5-2025-08-07-136", "response": {"status_code": 400, "request_id": "26c14e1e2d22a8bb4fa0584f26efd250", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcec9481909d04892e9d722031", "custom_id": "gpt-5-2025-08-07-137", "response": {"status_code": 400, "request_id": "459605ddae8a3b5005bc418cc743fac3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bceba08190b5467011dd5b3670", "custom_id": "gpt-5-2025-08-07-138", "response": {"status_code": 400, "request_id": "2343835cd1c2769248b301e9df148718", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd08c8819097b348c4b7287a05", "custom_id": "gpt-5-2025-08-07-139", "response": {"status_code": 400, "request_id": "27ddc62c0faa0f7a05ca1cd65ff9418b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bcfdf081909c53a6185df23eff", "custom_id": "gpt-5-2025-08-07-140", "response": {"status_code": 400, "request_id": "bb7613762305cf4fbe0d443a0e742e4a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd05648190a1af0164f5ceb39c", "custom_id": "gpt-5-2025-08-07-141", "response": {"status_code": 400, "request_id": "0e216cb96a1d2c365177656de10ff6d2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd25008190b021ea5bebb1ab5d", "custom_id": "gpt-5-2025-08-07-142", "response": {"status_code": 400, "request_id": "b655db8e415fc55a48843c6b42afaf84", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd34d88190aa7320b846ca76d5", "custom_id": "gpt-5-2025-08-07-143", "response": {"status_code": 400, "request_id": "2fda2937a83e2b12e5a088a5784f97be", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd4aa48190b17580b13c675266", "custom_id": "gpt-5-2025-08-07-144", "response": {"status_code": 400, "request_id": "a72c3164ffdb41fcfddbbc8ea11f3774", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd80408190a1e7db9506540956", "custom_id": "gpt-5-2025-08-07-145", "response": {"status_code": 400, "request_id": "673bfe5611ce0afd94840b5bf6a0329c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd68408190aecfa80aebb07174", "custom_id": "gpt-5-2025-08-07-146", "response": {"status_code": 400, "request_id": "6451b767edfd162b90a4edb651508c9f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd5fe48190853b666132115170", "custom_id": "gpt-5-2025-08-07-147", "response": {"status_code": 400, "request_id": "c1ea3145d030851e3c7e5e61d3776fd1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd66fc81909ee1f5b650b5deab", "custom_id": "gpt-5-2025-08-07-148", "response": {"status_code": 400, "request_id": "fe0dcc8e4743ae1f150e3477e90aaabb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd67a48190b03d81532fedc358", "custom_id": "gpt-5-2025-08-07-149", "response": {"status_code": 400, "request_id": "4b97978559e50a32ced80e6a6495ab86", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd7a7481908dfe1b789aa7e7af", "custom_id": "gpt-5-2025-08-07-150", "response": {"status_code": 400, "request_id": "0481c3f2fe99b126c9999513deb6dd11", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bd79548190b5014e318a02a87d", "custom_id": "gpt-5-2025-08-07-151", "response": {"status_code": 400, "request_id": "91f94873d24626e2475afc5e485f4cc0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611becb788190b7ab0d5e86bcca69", "custom_id": "gpt-5-2025-08-07-152", "response": {"status_code": 400, "request_id": "14cab10634f7c3b1f599f467fdea1632", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bda5f08190ba3f61741e879b63", "custom_id": "gpt-5-2025-08-07-153", "response": {"status_code": 400, "request_id": "96c999834085450caf2414b26995df9b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bdbed081909f9b8190d5896ae2", "custom_id": "gpt-5-2025-08-07-154", "response": {"status_code": 400, "request_id": "c9f642f4c44cca4880f231178c758cc2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c08c688190b01a3c35fc6c2b4b", "custom_id": "gpt-5-2025-08-07-155", "response": {"status_code": 400, "request_id": "8b55539c70cf653003bbf19c5b0dd353", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bdd06c8190b8012acc824b14a8", "custom_id": "gpt-5-2025-08-07-156", "response": {"status_code": 400, "request_id": "1b8399d89104bd6d153ef64382af19c8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bde3088190a8b14d29e19ad0cf", "custom_id": "gpt-5-2025-08-07-157", "response": {"status_code": 400, "request_id": "dd3f2221706c3ad416e140463cea7f86", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bdda288190abc1b71ea8e56f06", "custom_id": "gpt-5-2025-08-07-158", "response": {"status_code": 400, "request_id": "888fb11b032441f64863dda64e66ed9e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bde9cc8190b3e7cf3eddd1a2a7", "custom_id": "gpt-5-2025-08-07-159", "response": {"status_code": 400, "request_id": "8ba5426bc5a2642fd88b091b41fcebca", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bde5608190971d53b72005dca5", "custom_id": "gpt-5-2025-08-07-160", "response": {"status_code": 400, "request_id": "9d1e4820f4718e6a95d9f905309870b9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bdfe208190b269575d7d63d42c", "custom_id": "gpt-5-2025-08-07-161", "response": {"status_code": 400, "request_id": "1cedba223ae7c93e83631768c6f7a27b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf2ccc8190a25e190c22028368", "custom_id": "gpt-5-2025-08-07-162", "response": {"status_code": 400, "request_id": "bef6b13fb03ec497e3e95904626d94e2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be304c8190ad907c9891613bcb", "custom_id": "gpt-5-2025-08-07-163", "response": {"status_code": 400, "request_id": "096800d34c34b85e8f5feba811939e17", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be507481908ff635226b60d613", "custom_id": "gpt-5-2025-08-07-164", "response": {"status_code": 400, "request_id": "b348edc1bc77712ec4d2ad53e91f86e8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be49448190b91df06b89e13b1b", "custom_id": "gpt-5-2025-08-07-165", "response": {"status_code": 400, "request_id": "6a6a3c3345bddb05de6658a4f227dd41", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be5e7c81908810389ffb843011", "custom_id": "gpt-5-2025-08-07-166", "response": {"status_code": 400, "request_id": "8f7feb2f0919230d26dfc505bfd6b815", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be8824819086aa5a952d568ab4", "custom_id": "gpt-5-2025-08-07-167", "response": {"status_code": 400, "request_id": "0d8475919634cd47b0d79c2802a71cb6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be667481908d9a5caf1b9732ac", "custom_id": "gpt-5-2025-08-07-168", "response": {"status_code": 400, "request_id": "07dfa491b7ea6c7b3ae448953a8b18ec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be697481908c75d62929e1540b", "custom_id": "gpt-5-2025-08-07-169", "response": {"status_code": 400, "request_id": "74a42d938640711d2aaa7f1adb80af2d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611be99808190859e899c75edb9ed", "custom_id": "gpt-5-2025-08-07-170", "response": {"status_code": 400, "request_id": "d9a8956d874b1ebb1fca59d6c1056007", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611beb9a4819083732ddca831ccc2", "custom_id": "gpt-5-2025-08-07-171", "response": {"status_code": 400, "request_id": "ea7bb49a3fd572ee712b839766ba7a37", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bec4608190ac5c55691b0914da", "custom_id": "gpt-5-2025-08-07-172", "response": {"status_code": 400, "request_id": "8c75a30e45eaa3d19d8b36aa1f2f43c0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611beede88190b62df2c0c151f353", "custom_id": "gpt-5-2025-08-07-173", "response": {"status_code": 400, "request_id": "7cae497f38bdcd94e782d3181ef25732", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf08948190b32cd562c9611117", "custom_id": "gpt-5-2025-08-07-174", "response": {"status_code": 400, "request_id": "f6ba95bf752a4620a7ff5a754c757ff5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bed7b481909338911183190ec9", "custom_id": "gpt-5-2025-08-07-175", "response": {"status_code": 400, "request_id": "1e9431f92d71dc572cd345b23c8f061c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611befa988190b01e5d9588773a9f", "custom_id": "gpt-5-2025-08-07-176", "response": {"status_code": 400, "request_id": "93cbd8a2e4601be1e7cf8ecf00fbda8b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf09488190879d344a2cba1402", "custom_id": "gpt-5-2025-08-07-177", "response": {"status_code": 400, "request_id": "0917bdc37012dc54171b2fba5e5f2a9d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf332c8190b679a5f5cef23083", "custom_id": "gpt-5-2025-08-07-178", "response": {"status_code": 400, "request_id": "b3d8ffebce1fc3308e2094a20007711e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf363c8190ae7e20123607aaee", "custom_id": "gpt-5-2025-08-07-179", "response": {"status_code": 400, "request_id": "8005cac56b1ec26a01805a7f7fa727e1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf8db0819081e16696842de88a", "custom_id": "gpt-5-2025-08-07-180", "response": {"status_code": 400, "request_id": "7c7a47869c3300e6b0ff8a9e45052f4d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf4fa48190ac23d657c58897b5", "custom_id": "gpt-5-2025-08-07-181", "response": {"status_code": 400, "request_id": "d341d20c4066e3c752faaa49d271ab10", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c199d08190a6b68bc5997f57b0", "custom_id": "gpt-5-2025-08-07-182", "response": {"status_code": 400, "request_id": "1f3917863854c30bfb7fd4eacc33ce1e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf64b081909e98ad557472c08a", "custom_id": "gpt-5-2025-08-07-183", "response": {"status_code": 400, "request_id": "e4f60dde3ea0ed51f3daf1aa53c17696", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf83908190b838d218756b39a7", "custom_id": "gpt-5-2025-08-07-184", "response": {"status_code": 400, "request_id": "fbb849a50d843b0594651f6e9e3d7b03", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bf7f208190986b93880e4d2465", "custom_id": "gpt-5-2025-08-07-185", "response": {"status_code": 400, "request_id": "304d501881220b7f2777607b8772fa6a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bfbff08190a91bd49b2191050f", "custom_id": "gpt-5-2025-08-07-186", "response": {"status_code": 400, "request_id": "79e5767d2729a860f9b986169a6eb32e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bfa27c8190ad3dfba5dbbb123c", "custom_id": "gpt-5-2025-08-07-187", "response": {"status_code": 400, "request_id": "e0957af28460e3efdbd0185dc3e57cbb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bfa0448190a4a0b387341950c8", "custom_id": "gpt-5-2025-08-07-188", "response": {"status_code": 400, "request_id": "61933ca205deb844ccc49e3c05d8c4b5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bfbd1c8190a0ddd4002c8223ae", "custom_id": "gpt-5-2025-08-07-189", "response": {"status_code": 400, "request_id": "c282473d482690d95f7e39904875606d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bfcffc8190be03a8c76fb6d49f", "custom_id": "gpt-5-2025-08-07-190", "response": {"status_code": 400, "request_id": "80ff1b538e72ceb3f9260bf2987b3221", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c06aa88190a22656bdf2f605b6", "custom_id": "gpt-5-2025-08-07-191", "response": {"status_code": 400, "request_id": "b4797591985125343ebeedbddeaf653c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611bff06c8190b0d7ec55f323ff1b", "custom_id": "gpt-5-2025-08-07-192", "response": {"status_code": 400, "request_id": "068b9c13759ddf95bb405b4283e37a68", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0001881909f0c1cf2bac61060", "custom_id": "gpt-5-2025-08-07-193", "response": {"status_code": 400, "request_id": "239c5b2ff8cad65d5b68b3e6d3c3ed4f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0319c819087956e4a8263ca94", "custom_id": "gpt-5-2025-08-07-194", "response": {"status_code": 400, "request_id": "74deff1cfb27ca6c6b2d9b7956cca2fb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0144c8190a44f45c13877ec70", "custom_id": "gpt-5-2025-08-07-195", "response": {"status_code": 400, "request_id": "eb4c04b6f232ed572f39dc883ac00661", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c062cc8190a524892c1eaa3ae0", "custom_id": "gpt-5-2025-08-07-196", "response": {"status_code": 400, "request_id": "0c48a42be7fc7c83859a02536bb1dfe6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c030d8819086dd68c610bdc778", "custom_id": "gpt-5-2025-08-07-197", "response": {"status_code": 400, "request_id": "dacb7a4620268793c9d02f1831ff4966", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0453881909cd76ff948757c9b", "custom_id": "gpt-5-2025-08-07-198", "response": {"status_code": 400, "request_id": "bd834a05c3e896ffad64eb3bb9154eb9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0605081908aaa5c89f71dd9fa", "custom_id": "gpt-5-2025-08-07-199", "response": {"status_code": 400, "request_id": "9c3bc4e55859667ca0ecbc9d2f93a517", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c06c108190b401d3fba5952c99", "custom_id": "gpt-5-2025-08-07-200", "response": {"status_code": 400, "request_id": "c405fd41801848b08ced691b1afd07d4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c08f288190b4c6dec86283a42d", "custom_id": "gpt-5-2025-08-07-201", "response": {"status_code": 400, "request_id": "ccbd218bc67e474c2f4a44c090e4c8d0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0b6688190b53ddea34ba3f6a4", "custom_id": "gpt-5-2025-08-07-202", "response": {"status_code": 400, "request_id": "508b5aaa5ad77ee49ba5b615471a7cbe", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0b5988190952de19a8e8e370b", "custom_id": "gpt-5-2025-08-07-203", "response": {"status_code": 400, "request_id": "858571bb861182ea750c6dbd9dd532b1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0c15c8190bac97a004198527f", "custom_id": "gpt-5-2025-08-07-204", "response": {"status_code": 400, "request_id": "6296c9cc815f35a76bc6f77a0ac08c80", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0e1f48190a9aeb2356e307591", "custom_id": "gpt-5-2025-08-07-205", "response": {"status_code": 400, "request_id": "6010c3d13e13f93810b6d19302198869", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0e5308190a4fe537c64d69be3", "custom_id": "gpt-5-2025-08-07-206", "response": {"status_code": 400, "request_id": "d9966c597603b45a70fa4b9407f74bf7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0f0108190b54252bacd5789cd", "custom_id": "gpt-5-2025-08-07-207", "response": {"status_code": 400, "request_id": "a0d69bafd4b9dc84bbac3ea8dd7572d1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c0e2008190b2278399a6017c56", "custom_id": "gpt-5-2025-08-07-208", "response": {"status_code": 400, "request_id": "b9d7fcc0c76a2c68b2760b3b02125868", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c106108190a9c44bcb727fe885", "custom_id": "gpt-5-2025-08-07-209", "response": {"status_code": 400, "request_id": "0c637027841e8dc3862417bc61ef4e05", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c102508190806e9fdf9e1836e8", "custom_id": "gpt-5-2025-08-07-210", "response": {"status_code": 400, "request_id": "05b68daaf4ba4f415cd8422a7e7bc6ac", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1268881908acadb5334c461db", "custom_id": "gpt-5-2025-08-07-211", "response": {"status_code": 400, "request_id": "4102b9f57835ea74290c8795dad2ce84", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1273881909de0b9d4cb37ae7a", "custom_id": "gpt-5-2025-08-07-212", "response": {"status_code": 400, "request_id": "14b09f45a27c41909d942ae18935d003", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c12e9c8190a112fdf2fe5a3cb0", "custom_id": "gpt-5-2025-08-07-213", "response": {"status_code": 400, "request_id": "fea4ea495f24f95eb7ed00d3e4bfc2de", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c16cb08190af510527279ce72c", "custom_id": "gpt-5-2025-08-07-214", "response": {"status_code": 400, "request_id": "581c23ec837519c610f9e18c743ebe24", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c153e8819094a7c34a911afe42", "custom_id": "gpt-5-2025-08-07-215", "response": {"status_code": 400, "request_id": "d70280d923d7fc742c3cae526f1b57de", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c150d08190a5ffa66fb1548d3f", "custom_id": "gpt-5-2025-08-07-216", "response": {"status_code": 400, "request_id": "d861b086bb13247a6bcba76146ce7f4f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c15b548190870870186bf2079a", "custom_id": "gpt-5-2025-08-07-217", "response": {"status_code": 400, "request_id": "56d5bb1d150917aeb9702070cfbdc506", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1741c8190b80bf11b4434f438", "custom_id": "gpt-5-2025-08-07-218", "response": {"status_code": 400, "request_id": "5aba641a53aaf7f2cdd9378d8a89102d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c171ec8190a79a6e8756c75a66", "custom_id": "gpt-5-2025-08-07-219", "response": {"status_code": 400, "request_id": "24c245886524dfb328815b8ebfad3ff8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1b1a8819094199da48c919952", "custom_id": "gpt-5-2025-08-07-220", "response": {"status_code": 400, "request_id": "f084f6fbff952faf6b88ed1334a426ae", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2043881909f0fad7cb1c0e2f9", "custom_id": "gpt-5-2025-08-07-221", "response": {"status_code": 400, "request_id": "5adab39645b449c44ff1e3a2becbe62a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c199148190aa6572b087f74cd9", "custom_id": "gpt-5-2025-08-07-222", "response": {"status_code": 400, "request_id": "cbcaa9b0afbac9f0d36fcca65bb637d7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1b8148190990f15bac4336ed0", "custom_id": "gpt-5-2025-08-07-223", "response": {"status_code": 400, "request_id": "498bf827c5b3f85576119b4155dbe2ce", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1baa08190b39f978b1c66b64e", "custom_id": "gpt-5-2025-08-07-224", "response": {"status_code": 400, "request_id": "655bbc90176f02cd2d4b4d30677118f9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1c130819083f8bbcd48a77eb5", "custom_id": "gpt-5-2025-08-07-225", "response": {"status_code": 400, "request_id": "5b64df770e439a120b314449b9544be4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1e47881908238370c2784b103", "custom_id": "gpt-5-2025-08-07-226", "response": {"status_code": 400, "request_id": "743213d62e63e686d55cb5f49336afea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1e5b88190865aaf6fd4654ed5", "custom_id": "gpt-5-2025-08-07-227", "response": {"status_code": 400, "request_id": "4e6a3b3cf809f861d0235889660a3153", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c1e21881909f860967ef56a3c2", "custom_id": "gpt-5-2025-08-07-228", "response": {"status_code": 400, "request_id": "0ff0cc5ec936529211269c08fee16edf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2086881908d1432eb74370575", "custom_id": "gpt-5-2025-08-07-229", "response": {"status_code": 400, "request_id": "20a19b7f4cee38b9803e806b8c8ee63a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2050481909cc8793904835e64", "custom_id": "gpt-5-2025-08-07-230", "response": {"status_code": 400, "request_id": "01b9ba699b856132df4a8777315cc976", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c222dc819093419abfb6a62ee0", "custom_id": "gpt-5-2025-08-07-231", "response": {"status_code": 400, "request_id": "1904c3e3758eb91a8aadf84558f3747d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c31f408190abe13c9dcc70fc0c", "custom_id": "gpt-5-2025-08-07-232", "response": {"status_code": 400, "request_id": "94069e503e47f0d068431187b3ff4cdd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2a43c81908de5aaaad13b662e", "custom_id": "gpt-5-2025-08-07-233", "response": {"status_code": 400, "request_id": "c2dfc94fc7a2ff75861f47fc11bb9354", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c22aa08190898f09cebc28e8b6", "custom_id": "gpt-5-2025-08-07-234", "response": {"status_code": 400, "request_id": "dc4bc0ff38b57d69e302d526ba5589c1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c26d948190bbafdc3fbec45021", "custom_id": "gpt-5-2025-08-07-235", "response": {"status_code": 400, "request_id": "ebf9d6d818482e0375849ac05616d257", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c261b08190aa432e759e84572e", "custom_id": "gpt-5-2025-08-07-236", "response": {"status_code": 400, "request_id": "e018bb88caaf42c5502069d11c1701ca", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2693081908975db7da62a2347", "custom_id": "gpt-5-2025-08-07-237", "response": {"status_code": 400, "request_id": "2192aa9fdfb4e494c377c3c0b6ec94bf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c270b0819085c76f4b8aba8cac", "custom_id": "gpt-5-2025-08-07-238", "response": {"status_code": 400, "request_id": "4110ac4e6fedf579e309743b721a2c25", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2792c8190a002629c6b09a7e6", "custom_id": "gpt-5-2025-08-07-239", "response": {"status_code": 400, "request_id": "fbbd1281e0b81fa7bc529181c3eb6757", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c276a88190a76a0bf84f67a1ad", "custom_id": "gpt-5-2025-08-07-240", "response": {"status_code": 400, "request_id": "52cc5e63b15e9a5abf488f63fd931a7f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2c54c819080993b2499826148", "custom_id": "gpt-5-2025-08-07-241", "response": {"status_code": 400, "request_id": "60d2409081a9010f780014d9a03b5743", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2b5408190a7e19a46ff8e982f", "custom_id": "gpt-5-2025-08-07-242", "response": {"status_code": 400, "request_id": "e68b568a000a3314b93c8e7bd4f782da", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2e004819086ba11abfe1bd7cb", "custom_id": "gpt-5-2025-08-07-243", "response": {"status_code": 400, "request_id": "9a65831c17bbf696c3ba51ca25c246ac", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2dd6c8190ad672dcc012e1408", "custom_id": "gpt-5-2025-08-07-244", "response": {"status_code": 400, "request_id": "65238a2a5a92fb1c191da9ab54cd0e97", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2d7cc8190abcf4ccff41f2103", "custom_id": "gpt-5-2025-08-07-245", "response": {"status_code": 400, "request_id": "e6d373922be9a853ce32f055252ddab8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2dad48190a2e233f988431e37", "custom_id": "gpt-5-2025-08-07-246", "response": {"status_code": 400, "request_id": "81a152740b152da6a6edc7279fb94b16", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2e85c8190a3cb9966c45c1d12", "custom_id": "gpt-5-2025-08-07-247", "response": {"status_code": 400, "request_id": "510bffd81dd4cb02d7e9696002ed237b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c2e84c8190a38b3331f1b08739", "custom_id": "gpt-5-2025-08-07-248", "response": {"status_code": 400, "request_id": "29cb7a653c9aa8372741ae081b2b374d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c31b048190a228ceb05084b246", "custom_id": "gpt-5-2025-08-07-249", "response": {"status_code": 400, "request_id": "b27216dd10bee83eaafc03fa91d268e7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c333948190932a9c05bf1b8a63", "custom_id": "gpt-5-2025-08-07-250", "response": {"status_code": 400, "request_id": "d97deeb75880c869b9cb5d49c4a1d798", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c339d88190a599d51d455f5795", "custom_id": "gpt-5-2025-08-07-251", "response": {"status_code": 400, "request_id": "4c1a7e6ebec4c60530d4db6754bcc872", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c340b08190b62e61eba7f9b7a4", "custom_id": "gpt-5-2025-08-07-252", "response": {"status_code": 400, "request_id": "45b36fd1506be79d12799b93e316dedd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c34a248190a855f04c990cf926", "custom_id": "gpt-5-2025-08-07-253", "response": {"status_code": 400, "request_id": "906b62845cd9f961618074d06b2ef371", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c44a9c8190846334fe3796c97f", "custom_id": "gpt-5-2025-08-07-254", "response": {"status_code": 400, "request_id": "0e1b1ac8c933a95eb43bc1d0f03d02e9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c38ba8819088a4bf60c4c7f56c", "custom_id": "gpt-5-2025-08-07-255", "response": {"status_code": 400, "request_id": "c1342a89d5b1f72b61f9b796496dc49b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c355048190b53e49a478f293e6", "custom_id": "gpt-5-2025-08-07-256", "response": {"status_code": 400, "request_id": "67c27c90034f965e256ee969e56fd7a6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4b4588190b1a53ff6526615a6", "custom_id": "gpt-5-2025-08-07-257", "response": {"status_code": 400, "request_id": "bdb46e5ac7ae9c7b07616adc4124dc7d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c38a648190b06fe0592b11de04", "custom_id": "gpt-5-2025-08-07-258", "response": {"status_code": 400, "request_id": "48b09ea87adf2577c87fba0a39e2849b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c38f68819080b117d92812a843", "custom_id": "gpt-5-2025-08-07-259", "response": {"status_code": 400, "request_id": "8f777822c8c63a17a2010cac32cbd01c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3a3a48190871be32b5293be64", "custom_id": "gpt-5-2025-08-07-260", "response": {"status_code": 400, "request_id": "7ad5a314e411aa4c163411e33f6b8df6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3a98c819097a2dbdd7d3fbe08", "custom_id": "gpt-5-2025-08-07-261", "response": {"status_code": 400, "request_id": "efdfd014adf9f6341611ae0058b6f6d8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3dcd481908fca5b9c2b513427", "custom_id": "gpt-5-2025-08-07-262", "response": {"status_code": 400, "request_id": "f20b9077e348c70595181e6c4b80fec0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3b70c81908a0e3d00c354b316", "custom_id": "gpt-5-2025-08-07-263", "response": {"status_code": 400, "request_id": "3058049a9fda6f96d475dfa80dc33937", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3c2cc8190bf860ca126c853da", "custom_id": "gpt-5-2025-08-07-264", "response": {"status_code": 400, "request_id": "7fa188e7d2ac29983d2cb1d6ad4ba0f8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c3f36081908eef32dd4221134a", "custom_id": "gpt-5-2025-08-07-265", "response": {"status_code": 400, "request_id": "e0cf2b35c2dd5526d348f7f002b2b00c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4010881909b01e49f743a9ae9", "custom_id": "gpt-5-2025-08-07-266", "response": {"status_code": 400, "request_id": "7b4285d7d09d7a2489f4a80ee66d9448", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c40954819091745f4a95fa9d2c", "custom_id": "gpt-5-2025-08-07-267", "response": {"status_code": 400, "request_id": "df07886694d5a916676bc66877ed613e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c42f108190b41a22608ce28e69", "custom_id": "gpt-5-2025-08-07-268", "response": {"status_code": 400, "request_id": "0cbe947e5bf270003092b0c330ae84b6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c419948190802e4121b0881b1f", "custom_id": "gpt-5-2025-08-07-269", "response": {"status_code": 400, "request_id": "0ff17fa2d0d3fff8543ca4297334c8ae", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c437e08190a257e134fbe4fbd2", "custom_id": "gpt-5-2025-08-07-270", "response": {"status_code": 400, "request_id": "82f3529110ec9f6c01faf40f3f7d6692", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4364c8190a15594a73f3c1ed4", "custom_id": "gpt-5-2025-08-07-271", "response": {"status_code": 400, "request_id": "c990de9d79e4ca1b8fb7260991bb28b0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c666e481908b06f1d7a8233db2", "custom_id": "gpt-5-2025-08-07-272", "response": {"status_code": 400, "request_id": "5f96940316477f9bde2247f4e58dc797", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c466ec8190adc4834cad10d54d", "custom_id": "gpt-5-2025-08-07-273", "response": {"status_code": 400, "request_id": "4287e848fc063b4a42e1e164a1c2356f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4791c8190a75ddc8e75a2c584", "custom_id": "gpt-5-2025-08-07-274", "response": {"status_code": 400, "request_id": "74a6f1cdec2e2f4c75aa4e32986348db", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c47c948190830a36884cf1527a", "custom_id": "gpt-5-2025-08-07-275", "response": {"status_code": 400, "request_id": "9c1cb08721eebba286dfdee8ba3cb9a8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c48bb8819092808829831d3d1c", "custom_id": "gpt-5-2025-08-07-276", "response": {"status_code": 400, "request_id": "47b6c9f4d680ade495dbd5daecafb0b3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c494e08190b7f638dc618392d0", "custom_id": "gpt-5-2025-08-07-277", "response": {"status_code": 400, "request_id": "20cec42118b0fbb691318437f8906058", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4c5d881908ec5740747b0b67a", "custom_id": "gpt-5-2025-08-07-278", "response": {"status_code": 400, "request_id": "19a3ff73523058e6634def46da2bb974", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4aed081908b4315a55546cdcb", "custom_id": "gpt-5-2025-08-07-279", "response": {"status_code": 400, "request_id": "6522f8b39d88646c2ae03e5f9da76d97", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4be448190bb232e0231a2d73b", "custom_id": "gpt-5-2025-08-07-280", "response": {"status_code": 400, "request_id": "dae533333bc8c92497969ceb0ecedf16", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4de4c8190b03f9520f3d6a3ea", "custom_id": "gpt-5-2025-08-07-281", "response": {"status_code": 400, "request_id": "4d687a8dd2cdff5ed63e843d8a1a1f68", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4e724819087dc1eb0b27ef302", "custom_id": "gpt-5-2025-08-07-282", "response": {"status_code": 400, "request_id": "c99c8e2aaed59225dfb17f4236426d95", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4ebc08190b06b8afc782805d8", "custom_id": "gpt-5-2025-08-07-283", "response": {"status_code": 400, "request_id": "c65569aad4536c77602e8caa5c30a827", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c4fe78819092d64354a6e1503e", "custom_id": "gpt-5-2025-08-07-284", "response": {"status_code": 400, "request_id": "86577d22ed8051cbfc1b32e4d294c00d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c508648190bef43dabfd0146c1", "custom_id": "gpt-5-2025-08-07-285", "response": {"status_code": 400, "request_id": "786c79635baa1f5ed928b5ac1edfbb01", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c528788190bda7c17c75e76421", "custom_id": "gpt-5-2025-08-07-286", "response": {"status_code": 400, "request_id": "b95b84064191a41b6ae02e0ade9fd398", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c675408190b8686739501f0704", "custom_id": "gpt-5-2025-08-07-287", "response": {"status_code": 400, "request_id": "c40d60487c21933778438df48fed3132", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5307481908cae815d04ee8fa9", "custom_id": "gpt-5-2025-08-07-288", "response": {"status_code": 400, "request_id": "237e4d335910a7456753aa3e20c52286", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c537748190b07cd235a350db1f", "custom_id": "gpt-5-2025-08-07-289", "response": {"status_code": 400, "request_id": "87ef234720c7cf24e69f73d72423fd67", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c545988190ac80d7e2f9c5d2f0", "custom_id": "gpt-5-2025-08-07-290", "response": {"status_code": 400, "request_id": "13e9ba204f9d93f5c88f8281c17768be", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5537881909c630e9464ff612c", "custom_id": "gpt-5-2025-08-07-291", "response": {"status_code": 400, "request_id": "de7c746c4e23b520e18fd901fe5be6bd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c67c2881909b7a2a38c7e1182f", "custom_id": "gpt-5-2025-08-07-292", "response": {"status_code": 400, "request_id": "d89c4b8def035fd4f6924ae067868bb8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5fb58819087717710a52ab5a9", "custom_id": "gpt-5-2025-08-07-293", "response": {"status_code": 400, "request_id": "7d85ce2ab2ef39d861ed4486bc6b46af", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c573cc8190a4f169ec8b0560c7", "custom_id": "gpt-5-2025-08-07-294", "response": {"status_code": 400, "request_id": "62be75c151231941b79d87fccf5d49cc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5a30c81908ccc8498a365d828", "custom_id": "gpt-5-2025-08-07-295", "response": {"status_code": 400, "request_id": "8a50ddc509c55199f137727b0d158e9c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5a6888190835f3963853d9c31", "custom_id": "gpt-5-2025-08-07-296", "response": {"status_code": 400, "request_id": "88f213741b02cda4fef6cfe277a3c84c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5ab8881908e67cb86b116449c", "custom_id": "gpt-5-2025-08-07-297", "response": {"status_code": 400, "request_id": "2c414dcd6767e0f5d2c6d934f7cfa0d5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5ba80819085360e1dd84b9f29", "custom_id": "gpt-5-2025-08-07-298", "response": {"status_code": 400, "request_id": "ca8c71152146d4c4e8f097ad7c4d428d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5bf00819093811ee00501af42", "custom_id": "gpt-5-2025-08-07-299", "response": {"status_code": 400, "request_id": "ccc6cdd51b3255d15d66f8b834982137", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c5e0d08190948ffeab77a79d3b", "custom_id": "gpt-5-2025-08-07-300", "response": {"status_code": 400, "request_id": "49d7ed757ffb9e00c4ae286cf015e6b3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c60f088190ad4a3e72f8630668", "custom_id": "gpt-5-2025-08-07-301", "response": {"status_code": 400, "request_id": "e5c6789a65a27340af219c295321e244", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c61be48190ba8d2dab6e2619d5", "custom_id": "gpt-5-2025-08-07-302", "response": {"status_code": 400, "request_id": "87125d0905a8a0632de5caa5db593024", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c753048190aea241aca02d87cc", "custom_id": "gpt-5-2025-08-07-303", "response": {"status_code": 400, "request_id": "01effac32c3efe3eb10073bbdcc5b6bf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c62aa08190857b1e84d8e332d8", "custom_id": "gpt-5-2025-08-07-304", "response": {"status_code": 400, "request_id": "ff49059788a93b851d012e03de968ad1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c62ef08190a0179848ac295dda", "custom_id": "gpt-5-2025-08-07-305", "response": {"status_code": 400, "request_id": "9981cb92ce37d67f553f0db3c3bb25bb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c65f308190b83f6c94a4462775", "custom_id": "gpt-5-2025-08-07-306", "response": {"status_code": 400, "request_id": "aa2efd1bd9826795338c5b45b8247cf8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c66acc819083627a417941d98f", "custom_id": "gpt-5-2025-08-07-307", "response": {"status_code": 400, "request_id": "9cb0ff5f76d0fef0332635dc2999e2f2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c6967c81908649e9efa0128c25", "custom_id": "gpt-5-2025-08-07-308", "response": {"status_code": 400, "request_id": "6dfcabf8a5767237a1b52dcc61425b80", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c777248190b1cb90e2208e70b0", "custom_id": "gpt-5-2025-08-07-309", "response": {"status_code": 400, "request_id": "d544af9e400b1bc0ef359d3d486f85eb", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c69a388190bd4204ca3dabc745", "custom_id": "gpt-5-2025-08-07-310", "response": {"status_code": 400, "request_id": "65633cb5e0c0b262ee71fb2a1589f112", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c69978819081201c5604312b1a", "custom_id": "gpt-5-2025-08-07-311", "response": {"status_code": 400, "request_id": "bf9a30b74624106802b00d61d4e88a1e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c717a48190901035f756f83a1f", "custom_id": "gpt-5-2025-08-07-312", "response": {"status_code": 400, "request_id": "ac04dcd4ca3c67cd7a8046bbcbc9217a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c6e2e88190abeb8598dfb51c9c", "custom_id": "gpt-5-2025-08-07-313", "response": {"status_code": 400, "request_id": "cdbf9ab833a3ee81cc185a95bbdecbe7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c6e5408190bd5bef9be3fb6244", "custom_id": "gpt-5-2025-08-07-314", "response": {"status_code": 400, "request_id": "efc2dfd0267df4ef50e1b2b56f2a0198", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c6e4848190b08d6ba6f5323d2b", "custom_id": "gpt-5-2025-08-07-315", "response": {"status_code": 400, "request_id": "7f23d1ca5c8005ce0e85baa6595a8e2d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c70f508190b1f373c2b4dacf9c", "custom_id": "gpt-5-2025-08-07-316", "response": {"status_code": 400, "request_id": "7a4ec99747a05aed9d83e725621aa48b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7076481909dca5e0cef4782eb", "custom_id": "gpt-5-2025-08-07-317", "response": {"status_code": 400, "request_id": "6f758c5f539106216487e2dde1b8d7b9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7183c8190a0756eed2f124874", "custom_id": "gpt-5-2025-08-07-318", "response": {"status_code": 400, "request_id": "20dcef39cc0a52ac3cb2c59026581f38", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c70cf08190b65684998ca6ca38", "custom_id": "gpt-5-2025-08-07-319", "response": {"status_code": 400, "request_id": "40ad08396ed692849b2c6ce9f84370ef", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c75a408190a4c9df6c5a3d091f", "custom_id": "gpt-5-2025-08-07-320", "response": {"status_code": 400, "request_id": "354c7196210e37cee389bb7e9822bfec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c75d088190987055b4747c97e0", "custom_id": "gpt-5-2025-08-07-321", "response": {"status_code": 400, "request_id": "62dd962b92f5d95ef4f73226c05bcd0c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c758b48190a2486fe8ac7ca503", "custom_id": "gpt-5-2025-08-07-322", "response": {"status_code": 400, "request_id": "ac86bc51b7fd0ef55c6e8bfadcdf4992", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c773dc8190ba2b27ecdd8aa579", "custom_id": "gpt-5-2025-08-07-323", "response": {"status_code": 400, "request_id": "f90cce010decf8321ab631f11ef4b31f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c77e84819096dbc79f688b7ee6", "custom_id": "gpt-5-2025-08-07-324", "response": {"status_code": 400, "request_id": "478efa07d29a815cfcff81e3b0ecf440", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c79184819092c9506225f8a339", "custom_id": "gpt-5-2025-08-07-325", "response": {"status_code": 400, "request_id": "6c7dac32729f62bbbacedd19e2d17217", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c783d4819091d7f388650f3730", "custom_id": "gpt-5-2025-08-07-326", "response": {"status_code": 400, "request_id": "52c5c9ad054260e6ffa674e5e5dc95c6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c782cc8190bd1fec3466e155ae", "custom_id": "gpt-5-2025-08-07-327", "response": {"status_code": 400, "request_id": "9b05835c58030b7f3898aaa2f39671e8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7c6a88190aabcf9befd3bc482", "custom_id": "gpt-5-2025-08-07-328", "response": {"status_code": 400, "request_id": "6a3b10fc898e87766579e75b31b749fa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7c5308190899527a3f110ca6b", "custom_id": "gpt-5-2025-08-07-329", "response": {"status_code": 400, "request_id": "f33626e8524719b906331cd4ec1ae158", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7c3888190aa2655ceb61d1a1a", "custom_id": "gpt-5-2025-08-07-330", "response": {"status_code": 400, "request_id": "7c4ec53732a1c85733057cc91101b78e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7c1348190bb46a58763deab6f", "custom_id": "gpt-5-2025-08-07-331", "response": {"status_code": 400, "request_id": "5530fa6ca80b2a4286e05d53019ef0a2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7db008190b80e411d1dd223fc", "custom_id": "gpt-5-2025-08-07-332", "response": {"status_code": 400, "request_id": "e2f7be6da17fdd10d36cb2ed0bfc2dec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7e428819093ea9a0834a63f85", "custom_id": "gpt-5-2025-08-07-333", "response": {"status_code": 400, "request_id": "695ec3d0b1cf12c974d1f04538e130f5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c829fc8190a220f5785aeba546", "custom_id": "gpt-5-2025-08-07-334", "response": {"status_code": 400, "request_id": "c701834e66cb4a1c29db43c50adb92de", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7f99c81909fe370cd05ea5e41", "custom_id": "gpt-5-2025-08-07-335", "response": {"status_code": 400, "request_id": "373cae90ead58a032b14ae231530e71e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c7fc788190af695a05b9e2fd36", "custom_id": "gpt-5-2025-08-07-336", "response": {"status_code": 400, "request_id": "f6c1f05097b45adaa5a016c5a6ce64ab", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c83c408190a14a4b3dbfea9f51", "custom_id": "gpt-5-2025-08-07-337", "response": {"status_code": 400, "request_id": "c22636fbb027c7290338587433032f43", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c83734819085f30688891a31d2", "custom_id": "gpt-5-2025-08-07-338", "response": {"status_code": 400, "request_id": "ba385d348a51ebfc418304299eb97f8e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c84f14819098725d6a6559e8ca", "custom_id": "gpt-5-2025-08-07-339", "response": {"status_code": 400, "request_id": "b173d1235297ffa8b6858be494bf3dc3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c842f881908e0010194a8d6b14", "custom_id": "gpt-5-2025-08-07-340", "response": {"status_code": 400, "request_id": "8b747bcbb31578187efb3389ceaffc24", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c835b081909a6c16842122445b", "custom_id": "gpt-5-2025-08-07-341", "response": {"status_code": 400, "request_id": "0d2ce1c53cdfd632c5a4be06fa5870ec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c84e88819082fce97cc35c767b", "custom_id": "gpt-5-2025-08-07-342", "response": {"status_code": 400, "request_id": "d4229ac541c04cbaef2f3e5286d59245", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8649081909bfd0617cf2ee942", "custom_id": "gpt-5-2025-08-07-343", "response": {"status_code": 400, "request_id": "d2e68cc438af1651e49e3cc11b8138a6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c925ec8190879c8ac17b25b28e", "custom_id": "gpt-5-2025-08-07-344", "response": {"status_code": 400, "request_id": "091643198c1a54744433375f7c432417", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c86d588190bf495931ae28631a", "custom_id": "gpt-5-2025-08-07-345", "response": {"status_code": 400, "request_id": "957433d5f9008a0991a9bc196232470e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8971c8190845c7e0b4b1b600a", "custom_id": "gpt-5-2025-08-07-346", "response": {"status_code": 400, "request_id": "8404c6e9fc91745e10e52c6138d35e2a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8b1708190b432d0d514a19437", "custom_id": "gpt-5-2025-08-07-347", "response": {"status_code": 400, "request_id": "911647719e66f9610d8931fa904091b9", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8b520819080636613592c92ea", "custom_id": "gpt-5-2025-08-07-348", "response": {"status_code": 400, "request_id": "b2427040f6a7239e45e5904ab3171dc1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8b0b08190a1c3b7ff1f3e49e3", "custom_id": "gpt-5-2025-08-07-349", "response": {"status_code": 400, "request_id": "a23af85479070d37cfef37bb6ac2bfc6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8bf7c81909f8d7b24e3802cef", "custom_id": "gpt-5-2025-08-07-350", "response": {"status_code": 400, "request_id": "c5dbbdf515ed30d18286d7f112e56212", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8bf888190936e4810055ae3d0", "custom_id": "gpt-5-2025-08-07-351", "response": {"status_code": 400, "request_id": "196782dcd9f477f0902a565b319696fa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8c17c81909127038e62755b0f", "custom_id": "gpt-5-2025-08-07-352", "response": {"status_code": 400, "request_id": "3c9240d39137f70e4b93af4a4ea67429", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8d644819096c7c6d923863a59", "custom_id": "gpt-5-2025-08-07-353", "response": {"status_code": 400, "request_id": "f966f2b7ef2fcc2ff4ef823f0ea61cf2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c8ec048190a84e7bfa89687c97", "custom_id": "gpt-5-2025-08-07-354", "response": {"status_code": 400, "request_id": "1f44cbc4c4151e1b47590fbb446c37f6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c90ae08190b956f17e149c89aa", "custom_id": "gpt-5-2025-08-07-355", "response": {"status_code": 400, "request_id": "c9c7435ce0386f70adf4219cd55e5697", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c923088190a5da74a08dc0a42d", "custom_id": "gpt-5-2025-08-07-356", "response": {"status_code": 400, "request_id": "3d024ebb6591448d9d4f6d00ea96b0c8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9278c81908d17f4b18f656bd7", "custom_id": "gpt-5-2025-08-07-357", "response": {"status_code": 400, "request_id": "afa9a3a9975afee755662c98136a2bce", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c925488190b2dd5a352529f1fa", "custom_id": "gpt-5-2025-08-07-358", "response": {"status_code": 400, "request_id": "da36cac23ffbacbf4085befc9d65ba84", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c93b30819081a806398e674bfe", "custom_id": "gpt-5-2025-08-07-359", "response": {"status_code": 400, "request_id": "4102ab15837e7e30b2a3e63bc95ac5bd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9284c81908ed91696f933d58d", "custom_id": "gpt-5-2025-08-07-360", "response": {"status_code": 400, "request_id": "d14d76888d3f9824520976d8b28b0b01", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c932a081908d2053ecf109a869", "custom_id": "gpt-5-2025-08-07-361", "response": {"status_code": 400, "request_id": "87d05f51e32eb54e5ed2f226a77ee378", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c947d8819083e80fbf42ce0e35", "custom_id": "gpt-5-2025-08-07-362", "response": {"status_code": 400, "request_id": "fc9a4d16912ad1fbaca5b26f0995175a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c95ab881909e1d14c98473b6ed", "custom_id": "gpt-5-2025-08-07-363", "response": {"status_code": 400, "request_id": "fa45b24102c9cc2c341a98483c1289c3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9826c8190b3b4c0836eb78af7", "custom_id": "gpt-5-2025-08-07-364", "response": {"status_code": 400, "request_id": "81a5424ea5dfe951e4d8db2c69b5e18b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9cb208190a5aea5782e0429b5", "custom_id": "gpt-5-2025-08-07-365", "response": {"status_code": 400, "request_id": "886ceec644f6f32ce5c8ef583b105bdc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c993188190a6e64305abcebb12", "custom_id": "gpt-5-2025-08-07-366", "response": {"status_code": 400, "request_id": "768f1ddcbe1cf291f8f5c3e9b66ec3a6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c99bb88190890305263ba30100", "custom_id": "gpt-5-2025-08-07-367", "response": {"status_code": 400, "request_id": "173fdce4c8a0c92b4770403fe56efdf1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb295481908df41399e209d4b6", "custom_id": "gpt-5-2025-08-07-368", "response": {"status_code": 400, "request_id": "14ff72d41397ce89130cf9e2a60ddb1a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c997508190aee4e84d6ee8715c", "custom_id": "gpt-5-2025-08-07-369", "response": {"status_code": 400, "request_id": "2f4e64e4c426e7fd0b842bea6a02fe07", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9a3148190aa2ee38213db117d", "custom_id": "gpt-5-2025-08-07-370", "response": {"status_code": 400, "request_id": "708f18ad5cc145472f0b3aaf03fedfdf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9ab7081908159f5ae55bc18ad", "custom_id": "gpt-5-2025-08-07-371", "response": {"status_code": 400, "request_id": "956e7e8c38801f132a5ae4845216d316", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9b2448190a500c7dd27f464ae", "custom_id": "gpt-5-2025-08-07-372", "response": {"status_code": 400, "request_id": "780e9553400b7fee1199dc0292f5c278", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611c9cbb08190a9bc2e5b04f1f3f6", "custom_id": "gpt-5-2025-08-07-373", "response": {"status_code": 400, "request_id": "a624518a6de58397a2b70ed55b080c22", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca042081908c6df3cc93cfd2f3", "custom_id": "gpt-5-2025-08-07-374", "response": {"status_code": 400, "request_id": "50998bc4c95ecea5aa11856b831f3bba", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca03908190b64ef3f18e4514b4", "custom_id": "gpt-5-2025-08-07-375", "response": {"status_code": 400, "request_id": "b72b190f9f033f7141b34a4db9815ae6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca16688190ad3cf6e71d2300b3", "custom_id": "gpt-5-2025-08-07-376", "response": {"status_code": 400, "request_id": "225cd6657bc7687502900caaaaed8faf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca09dc8190a2bbd92ab09aae24", "custom_id": "gpt-5-2025-08-07-377", "response": {"status_code": 400, "request_id": "c4a1d780a21915357a980405ed2f7114", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca08848190abb27ac6077d11bf", "custom_id": "gpt-5-2025-08-07-378", "response": {"status_code": 400, "request_id": "32be63e5dfa2855c381470f8a1c6197f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca18e88190a1616d6f17f13748", "custom_id": "gpt-5-2025-08-07-379", "response": {"status_code": 400, "request_id": "93a9e8b5dad3409f95c948b6c898b321", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca1a548190ad38708808a46823", "custom_id": "gpt-5-2025-08-07-380", "response": {"status_code": 400, "request_id": "2e1a486b82634b31bc4d7962bd2f6b7c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca3b1c8190badc1848c255ec7e", "custom_id": "gpt-5-2025-08-07-381", "response": {"status_code": 400, "request_id": "72e833b9594a4c05efb1783eef22dfb7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca3c00819093a7a7483953274f", "custom_id": "gpt-5-2025-08-07-382", "response": {"status_code": 400, "request_id": "7609552a8b7d526df476b402f728e6bc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca76b0819084ae939a2faf8292", "custom_id": "gpt-5-2025-08-07-383", "response": {"status_code": 400, "request_id": "e18006604553f053f18e425410e10d8a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca80d08190baede48052ff122b", "custom_id": "gpt-5-2025-08-07-384", "response": {"status_code": 400, "request_id": "a659d597cc5c3f1ef2cadec225301d33", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca7c508190b040f87f9093d80f", "custom_id": "gpt-5-2025-08-07-385", "response": {"status_code": 400, "request_id": "7796776c420639ebb61243061ca69ae8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca7d508190b7921ffb494ac2ff", "custom_id": "gpt-5-2025-08-07-386", "response": {"status_code": 400, "request_id": "895f4eda0698ec271329adb110ea6954", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca88448190b48894b326494807", "custom_id": "gpt-5-2025-08-07-387", "response": {"status_code": 400, "request_id": "574fcc7ef0d0849f33ba8c86c2e3230b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca88cc8190b530cfcc1112d74e", "custom_id": "gpt-5-2025-08-07-388", "response": {"status_code": 400, "request_id": "ef148d8e78145be77da68aa3742ec247", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ca8474819085f5057978df3f37", "custom_id": "gpt-5-2025-08-07-389", "response": {"status_code": 400, "request_id": "ce27fd55621f65ce38978cc7152539c4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cab28c81909545fce530873a76", "custom_id": "gpt-5-2025-08-07-390", "response": {"status_code": 400, "request_id": "6e3533af04bbcfeb5e5584590484cf36", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611caa7dc81908fc12ed398916131", "custom_id": "gpt-5-2025-08-07-391", "response": {"status_code": 400, "request_id": "503b35ef0dddabc22218e34c5b8e5284", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cadc0c8190a748870e3a8abe27", "custom_id": "gpt-5-2025-08-07-392", "response": {"status_code": 400, "request_id": "ad46d563c9aa7adab61aa475b065e894", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611caee248190a30de05121f47322", "custom_id": "gpt-5-2025-08-07-393", "response": {"status_code": 400, "request_id": "07d329db6dd3eaf51d76fa9a1009abb4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb00388190b806dcac72e1524b", "custom_id": "gpt-5-2025-08-07-394", "response": {"status_code": 400, "request_id": "c67584db0d4d49542f4d8502fd91e681", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611caee30819091f7137d3274d5a5", "custom_id": "gpt-5-2025-08-07-395", "response": {"status_code": 400, "request_id": "b1d8d879c6d3e3cf21f78a7b9b1901b2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611caf4508190af6bda1e04483793", "custom_id": "gpt-5-2025-08-07-396", "response": {"status_code": 400, "request_id": "68310f2748c0c681995512241ebbffb2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb22388190a8824fd6a8cf6a5b", "custom_id": "gpt-5-2025-08-07-397", "response": {"status_code": 400, "request_id": "c29b3f69a2c860148411de8d254a678f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb24d881909c9d33d0662d90dc", "custom_id": "gpt-5-2025-08-07-398", "response": {"status_code": 400, "request_id": "e19a25a18f23ee5a25db27ac2460dc5a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cc3538819090d2c8297743d82b", "custom_id": "gpt-5-2025-08-07-399", "response": {"status_code": 400, "request_id": "43b3b65037e1c2327fa6ec4deb989906", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb274c81908d5898c308fc448e", "custom_id": "gpt-5-2025-08-07-400", "response": {"status_code": 400, "request_id": "0b8c15f4d85c2040b0c518878110aeb8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb4ad88190948066ac26191457", "custom_id": "gpt-5-2025-08-07-401", "response": {"status_code": 400, "request_id": "94bf65b290210e45b8f229d5d26e35e5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccf298819095e3357051e6d29e", "custom_id": "gpt-5-2025-08-07-402", "response": {"status_code": 400, "request_id": "f315f936feef42641bfe35fb36d6e1ec", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb5bc08190bb26893039dba2dd", "custom_id": "gpt-5-2025-08-07-403", "response": {"status_code": 400, "request_id": "6d57dd5421fa86e3d481d6b48a983455", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb69d481909edeb1d9380be039", "custom_id": "gpt-5-2025-08-07-404", "response": {"status_code": 400, "request_id": "f3bef48da3ad4eb3df4c5d94cf505130", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb75b4819097e06461ad131bf7", "custom_id": "gpt-5-2025-08-07-405", "response": {"status_code": 400, "request_id": "27da6bc84fdc8b81e64414986f4c74ab", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccc38c8190a8cfe4961714fbb8", "custom_id": "gpt-5-2025-08-07-406", "response": {"status_code": 400, "request_id": "834ee39c3c88339aaf5cf46b08637b3c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cbb0ec8190aadecdceccc4ef5b", "custom_id": "gpt-5-2025-08-07-407", "response": {"status_code": 400, "request_id": "f1bca9335423af5d97667d80ea452a34", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd4cbc8190ad463a913b794e8b", "custom_id": "gpt-5-2025-08-07-408", "response": {"status_code": 400, "request_id": "d119ab214fd2e127995b9b57ff58d042", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cb91c48190953143f3905b2428", "custom_id": "gpt-5-2025-08-07-409", "response": {"status_code": 400, "request_id": "259ac0ba4ed41ae18d20f047e21a6a42", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cbb8b08190a2b54e4c79e17056", "custom_id": "gpt-5-2025-08-07-410", "response": {"status_code": 400, "request_id": "3534f555e279e0ed1fec3575bb873739", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cbd5808190acf42edbb1ac9d9f", "custom_id": "gpt-5-2025-08-07-411", "response": {"status_code": 400, "request_id": "b3fd451230321618cfe62290fb1ee9b2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cbd93c8190912783dc3381dfd1", "custom_id": "gpt-5-2025-08-07-412", "response": {"status_code": 400, "request_id": "5fdca00a8c584bb20d913948933e61ba", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cbe6148190935a69cc5d62a8fc", "custom_id": "gpt-5-2025-08-07-413", "response": {"status_code": 400, "request_id": "bfa80e6ec26a9d746761c32c6810f07c", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cc00448190b9828cc8f7d4930e", "custom_id": "gpt-5-2025-08-07-414", "response": {"status_code": 400, "request_id": "cfe323394fb267dc858ef86574a64aad", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cc1fa881909b63029a73e41f63", "custom_id": "gpt-5-2025-08-07-415", "response": {"status_code": 400, "request_id": "1bdcba37cd5dfefe47bd123ae0da30b3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cc2f7081909357010e8e51b01b", "custom_id": "gpt-5-2025-08-07-416", "response": {"status_code": 400, "request_id": "22fcb61224748d0f44b9c5734b8a23bd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cc3870819088709ae5648da3c0", "custom_id": "gpt-5-2025-08-07-417", "response": {"status_code": 400, "request_id": "c38dc650d746ae91aa80cfdfab9564cf", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccb5a88190bc6d7eb9bf6d197e", "custom_id": "gpt-5-2025-08-07-418", "response": {"status_code": 400, "request_id": "98c5c0a3928d3a6ed85801349e9fcd74", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cca78881909747489c69685fbb", "custom_id": "gpt-5-2025-08-07-419", "response": {"status_code": 400, "request_id": "70950ff71664557cc8b3485655c79ee4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccda1481909d947ce9340651f4", "custom_id": "gpt-5-2025-08-07-420", "response": {"status_code": 400, "request_id": "553fb55e183b7321b2fa3a20cebd8079", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cce8b88190af45954d0b113173", "custom_id": "gpt-5-2025-08-07-421", "response": {"status_code": 400, "request_id": "4b4ac569a4e8c93c254ed884ac5546e8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccf93c8190a85c73a57f0d28b1", "custom_id": "gpt-5-2025-08-07-422", "response": {"status_code": 400, "request_id": "93eb5f06f554c567c609c4612a23b11a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccf354819096f61c3fb544aae8", "custom_id": "gpt-5-2025-08-07-423", "response": {"status_code": 400, "request_id": "c80c20af95387501e5f8d4a8612d3900", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ccf5b481909509fea3870c32c6", "custom_id": "gpt-5-2025-08-07-424", "response": {"status_code": 400, "request_id": "8b55a99498514621d74757ae23869ca2", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd18a081908bad8f05e4eebdb1", "custom_id": "gpt-5-2025-08-07-425", "response": {"status_code": 400, "request_id": "ef2e66d9d80d22efa2a1ab1506349317", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd880c81909c5d8ba01207116d", "custom_id": "gpt-5-2025-08-07-426", "response": {"status_code": 400, "request_id": "91fb5e82f6e2c50ff42b2448f0ef5562", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd8f688190a604d4754bb0c75d", "custom_id": "gpt-5-2025-08-07-427", "response": {"status_code": 400, "request_id": "1514beb766084aedd7014eaf911862cc", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd4be081908ec1823d1bc5967a", "custom_id": "gpt-5-2025-08-07-428", "response": {"status_code": 400, "request_id": "ddd241d34b867770676375753c30efd8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd60388190a4dd1653bc62e83a", "custom_id": "gpt-5-2025-08-07-429", "response": {"status_code": 400, "request_id": "fee4a1b199970872adc1976d7bc90f37", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd77cc8190b30752bcf8e1ef6b", "custom_id": "gpt-5-2025-08-07-430", "response": {"status_code": 400, "request_id": "cc28921029b62a13d0cf06a8d2607a27", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd6800819082353ca45a1ab8d0", "custom_id": "gpt-5-2025-08-07-431", "response": {"status_code": 400, "request_id": "12168e00208377038b059dedb43f3c6b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd6030819098922430e3cdfe11", "custom_id": "gpt-5-2025-08-07-432", "response": {"status_code": 400, "request_id": "24bf1e53cc63dcdb3072228c79a3d5b7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd6a68819082411f5e32317614", "custom_id": "gpt-5-2025-08-07-433", "response": {"status_code": 400, "request_id": "679871beede7107b8d4e3e4573a7d855", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cd7f448190b62a5703e51e7353", "custom_id": "gpt-5-2025-08-07-434", "response": {"status_code": 400, "request_id": "c907d7f4ebbca04d7f5427173ffea000", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cdc9b481908b2b1e52a67444d3", "custom_id": "gpt-5-2025-08-07-435", "response": {"status_code": 400, "request_id": "06d17bdd427bdc1270fe5b43e2972eb3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cdb9c08190ad4cedee7d04b658", "custom_id": "gpt-5-2025-08-07-436", "response": {"status_code": 400, "request_id": "d99fc19e4906a2b5f4a77e9dad2a4d23", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf28d88190bf5fb71cb1f72ea1", "custom_id": "gpt-5-2025-08-07-437", "response": {"status_code": 400, "request_id": "859f5b277f01d7bff13b7be31dcd984e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cdf3c481908dcb65d77c27f5ef", "custom_id": "gpt-5-2025-08-07-438", "response": {"status_code": 400, "request_id": "ed81c51e7618f82f674a7f05af4152d7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cde8cc8190a51d38f04e29a03c", "custom_id": "gpt-5-2025-08-07-439", "response": {"status_code": 400, "request_id": "d0175247b99aa74f1294a3893d183f88", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cdda8c8190ab434616c52b3c47", "custom_id": "gpt-5-2025-08-07-440", "response": {"status_code": 400, "request_id": "551f87bbcc92eee5ba9e8857d2d4b5a5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cde96c81908dab47c8320561f5", "custom_id": "gpt-5-2025-08-07-441", "response": {"status_code": 400, "request_id": "9318344adaa3627e8942007eb4d654f5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cdef788190af765048c93aacdd", "custom_id": "gpt-5-2025-08-07-442", "response": {"status_code": 400, "request_id": "f7764b08d1cb4d0d920019e4a72f46f1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf6d7481908f7a6b3f6b025bb4", "custom_id": "gpt-5-2025-08-07-443", "response": {"status_code": 400, "request_id": "251b5a0c8c274df83247542cf65b8f86", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce07588190a1fc37de36b8c90c", "custom_id": "gpt-5-2025-08-07-444", "response": {"status_code": 400, "request_id": "61124a43dd0c57ff5284acbd6cc2a173", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce2b8c8190bd18bdf4954200d3", "custom_id": "gpt-5-2025-08-07-445", "response": {"status_code": 400, "request_id": "6052f9134b0f979cfec3c6b23bb3dcc1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce43348190a5e78aae1fc5c202", "custom_id": "gpt-5-2025-08-07-446", "response": {"status_code": 400, "request_id": "73e94f36d1bf5f84c120cf30cbeb3a31", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce4b888190a1286ee145398e71", "custom_id": "gpt-5-2025-08-07-447", "response": {"status_code": 400, "request_id": "51a29c055df233ac3aec4a0129109639", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce4f688190ba7eea614b676ff3", "custom_id": "gpt-5-2025-08-07-448", "response": {"status_code": 400, "request_id": "545743228cc023f4de20cd5f317c72e5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce542881908047a30faf08090c", "custom_id": "gpt-5-2025-08-07-449", "response": {"status_code": 400, "request_id": "484975639bbb481440de2008024b6b08", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce613081909ce4ed7603a0dd29", "custom_id": "gpt-5-2025-08-07-450", "response": {"status_code": 400, "request_id": "95d95d7a9b76c1a331c282d7bdb6fee5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ce5fe08190b36b90f63e6c35b6", "custom_id": "gpt-5-2025-08-07-451", "response": {"status_code": 400, "request_id": "f577d93ec0a8c0ebcd2e4a57872c8a6e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cebb0881908be7953f4e2e0f26", "custom_id": "gpt-5-2025-08-07-452", "response": {"status_code": 400, "request_id": "746be894aaf9165fe5d16d103039b860", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ced72c819083d52d12cbb7a8ce", "custom_id": "gpt-5-2025-08-07-453", "response": {"status_code": 400, "request_id": "bb98b11bb0f199476ec375a33eace69b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ceb208819087e349f3094fb6eb", "custom_id": "gpt-5-2025-08-07-454", "response": {"status_code": 400, "request_id": "4a901bec430888a2c0618e91ed988a20", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ceb83081908d5e8813c9c1b7ad", "custom_id": "gpt-5-2025-08-07-455", "response": {"status_code": 400, "request_id": "50248378b93df9364d75ed90382f3f4f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cec1a8819084b147b512df3eae", "custom_id": "gpt-5-2025-08-07-456", "response": {"status_code": 400, "request_id": "e71e8a5f62118d623e30a3dbd7a407c0", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf0e448190b823d9e0d897365f", "custom_id": "gpt-5-2025-08-07-457", "response": {"status_code": 400, "request_id": "e47cd18048b999f9c3aa8e7287a573a3", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ced4648190a4b8d663111118c8", "custom_id": "gpt-5-2025-08-07-458", "response": {"status_code": 400, "request_id": "2312d9207398df304c78f94d2f9e1999", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611ced37c81909ac1236c5149d46e", "custom_id": "gpt-5-2025-08-07-459", "response": {"status_code": 400, "request_id": "e5b54956e65cf5dd1fdca7b95f170312", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d16f2881909f26eda7256ea712", "custom_id": "gpt-5-2025-08-07-460", "response": {"status_code": 400, "request_id": "41fa01306c4ae03d3e3e2e12f950fb27", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf1e7c819086c32463da4812c2", "custom_id": "gpt-5-2025-08-07-461", "response": {"status_code": 400, "request_id": "aa8c3367529679c6b0d7cedecd114676", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf296c8190bdc64b0ec006f74b", "custom_id": "gpt-5-2025-08-07-462", "response": {"status_code": 400, "request_id": "cd4f83be90b1d63fa16134c81d12a792", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d0af108190a3b5ffa196214e35", "custom_id": "gpt-5-2025-08-07-463", "response": {"status_code": 400, "request_id": "6b9c200bdd1001990e3ca3151b147a76", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf477881909127e4775d43f45d", "custom_id": "gpt-5-2025-08-07-464", "response": {"status_code": 400, "request_id": "1fa0c82ab715a43ae74bb5b0e8fc32aa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf43cc8190890c28e339f7603f", "custom_id": "gpt-5-2025-08-07-465", "response": {"status_code": 400, "request_id": "9e68239ddf32a76cd43c3bfd7cb9c900", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf55e08190862c908efed260d6", "custom_id": "gpt-5-2025-08-07-466", "response": {"status_code": 400, "request_id": "208bfeec952bc149dc56fc616e8216e8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf85ec81909d92d565cb59fb39", "custom_id": "gpt-5-2025-08-07-467", "response": {"status_code": 400, "request_id": "06ea46a5f195ffe495cc6101fde1082d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d0b41481908a86704958dc711c", "custom_id": "gpt-5-2025-08-07-468", "response": {"status_code": 400, "request_id": "a4abef01eaa2b712c8d6320424071bbd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf91888190ad84aa620f52ffb0", "custom_id": "gpt-5-2025-08-07-469", "response": {"status_code": 400, "request_id": "bc1f6a2a568d476ac0e78d2bda6432f8", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cf9a3481909c8d71a3a17c94e2", "custom_id": "gpt-5-2025-08-07-470", "response": {"status_code": 400, "request_id": "91f6da0630c99a414914741f61640a8b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cfd25c8190baeb7ba336dacc6a", "custom_id": "gpt-5-2025-08-07-471", "response": {"status_code": 400, "request_id": "0f9d34b5bcbf7394468ed35bca860dc1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cfbcac8190b8d09f9410ac3d00", "custom_id": "gpt-5-2025-08-07-472", "response": {"status_code": 400, "request_id": "10815db2f090b144a21ccd39db418d90", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cfc3948190b75b28d7d0bacbd3", "custom_id": "gpt-5-2025-08-07-473", "response": {"status_code": 400, "request_id": "7b1ecd333ab2f31f6548a07750a99f64", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611cfdb9c819089c9cc95b6a8020b", "custom_id": "gpt-5-2025-08-07-474", "response": {"status_code": 400, "request_id": "7a0b318c027d733447cd1bf3efd23442", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d094188190a481fa63414958df", "custom_id": "gpt-5-2025-08-07-475", "response": {"status_code": 400, "request_id": "fbba396ed444eae1742e492c6d98a55e", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d095ac8190a4602e95c77a8159", "custom_id": "gpt-5-2025-08-07-476", "response": {"status_code": 400, "request_id": "898cd89228a6f6b11473e692db04304b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d0b8ac8190ba0c5346928f40fc", "custom_id": "gpt-5-2025-08-07-477", "response": {"status_code": 400, "request_id": "9affddeb4e4b78e2de10dc2d944d417f", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d0bd308190b2221b9450c9a8c0", "custom_id": "gpt-5-2025-08-07-478", "response": {"status_code": 400, "request_id": "01bcb99edcafd50c53cb0e336624b3d7", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d0d03c8190926941f4645ad5e2", "custom_id": "gpt-5-2025-08-07-479", "response": {"status_code": 400, "request_id": "e540b849174af71615e70707b4276a8d", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d215ec819089581aeecc695c24", "custom_id": "gpt-5-2025-08-07-480", "response": {"status_code": 400, "request_id": "1c81d8a3f7912db8e486d5d8de22505a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1755081908c7859e8c9ea8205", "custom_id": "gpt-5-2025-08-07-481", "response": {"status_code": 400, "request_id": "1a7a1666b1d08427c8866575d9b3d1b5", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1c7c4819091d192b72df9a3ce", "custom_id": "gpt-5-2025-08-07-482", "response": {"status_code": 400, "request_id": "21c1f5ed0bece7ed054fc6756c4183d4", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1c06c819091738e49ca15cf37", "custom_id": "gpt-5-2025-08-07-483", "response": {"status_code": 400, "request_id": "a22d790ab22b5c799805784670d82527", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1e2188190afaff08319d50092", "custom_id": "gpt-5-2025-08-07-484", "response": {"status_code": 400, "request_id": "7dff4c18b198a5aefbfbf5754e817d43", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1ed1c8190a1a4b06eb3c2cd9b", "custom_id": "gpt-5-2025-08-07-485", "response": {"status_code": 400, "request_id": "0e3dca74c75ccd911f1ca7fb87aa8c86", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1f87c8190ae1d778431e2f932", "custom_id": "gpt-5-2025-08-07-486", "response": {"status_code": 400, "request_id": "1d49b2cda4cc537194be21398b936c81", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1f4e48190b4d9efe4ef4bf217", "custom_id": "gpt-5-2025-08-07-487", "response": {"status_code": 400, "request_id": "39417113380ba32dc2a293099d05712b", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d1fa648190912480eebf093ea2", "custom_id": "gpt-5-2025-08-07-488", "response": {"status_code": 400, "request_id": "5781e8eb3e0c4ae01ab944a5a90082e6", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d2181c81909caf874c9d02d59e", "custom_id": "gpt-5-2025-08-07-489", "response": {"status_code": 400, "request_id": "8ca503c4661c47983b2b75a42793731a", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d20e148190b15910fc2cb1aabb", "custom_id": "gpt-5-2025-08-07-490", "response": {"status_code": 400, "request_id": "cae1ad8220478299933b6de1e5100f03", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d22de4819091be3201204293fc", "custom_id": "gpt-5-2025-08-07-491", "response": {"status_code": 400, "request_id": "008888d05361944ba2b43d20e161fefa", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d22f1881909525b441e91d6aba", "custom_id": "gpt-5-2025-08-07-492", "response": {"status_code": 400, "request_id": "2c0046ea79b8789b286b0cde59f070df", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d24b948190a2f2828fcf1d8996", "custom_id": "gpt-5-2025-08-07-493", "response": {"status_code": 400, "request_id": "931871366947f5b89b576886ba4fb999", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d250688190b162e554efee7c23", "custom_id": "gpt-5-2025-08-07-494", "response": {"status_code": 400, "request_id": "4047cbb700892cd98559d9b3ed1e4df1", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d26e188190bab278a1900fdb5a", "custom_id": "gpt-5-2025-08-07-495", "response": {"status_code": 400, "request_id": "f9cfa00e5fdc236f71fa86094352cdea", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d2a44081908a01c825520e56c0", "custom_id": "gpt-5-2025-08-07-496", "response": {"status_code": 400, "request_id": "e46f9a00c64e91f1d9ace0044b85a644", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d26ecc81908161ec8d2a3e3a2e", "custom_id": "gpt-5-2025-08-07-497", "response": {"status_code": 400, "request_id": "7f4283f02fc540768cfdd35fac2046fd", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d283f88190bd7893c835ff3b43", "custom_id": "gpt-5-2025-08-07-498", "response": {"status_code": 400, "request_id": "862c583dd6e9bf790ced1ba9469f2c18", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
{"id": "batch_req_692611d288c0819086fc7a0ee4ccc376", "custom_id": "gpt-5-2025-08-07-499", "response": {"status_code": 400, "request_id": "ff9cbb0d6b69bd974fe79fe8ec3893fe", "body": {"error": {"message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", "type": "invalid_request_error", "param": "max_tokens", "code": "unsupported_parameter"}}}, "error": null}
